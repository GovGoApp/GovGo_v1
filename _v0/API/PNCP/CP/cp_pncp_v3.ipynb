{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:44:37.885 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import io\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# ============================================\n",
    "# Funções auxiliares\n",
    "# ============================================\n",
    "\n",
    "def fetch_processos(data_inicial, data_final, codigo_modalidade, tamanho_pagina, ufs):\n",
    "    \"\"\"\n",
    "    Realiza a consulta na API PNCP para cada UF informada.\n",
    "    Para cada UF, obtém o total de páginas e itera por todas elas,\n",
    "    coletando o dicionário completo de cada processo.\n",
    "    \"\"\"\n",
    "    base_url = 'https://pncp.gov.br/api/consulta/v1/contratacoes/publicacao'\n",
    "    processos = []\n",
    "    for uf in ufs:\n",
    "        url_inicial = f\"{base_url}?dataInicial={data_inicial}&dataFinal={data_final}&codigoModalidadeContratacao={codigo_modalidade}&uf={uf}&tamanhoPagina={tamanho_pagina}&pagina=1\"\n",
    "        response_inicial = requests.get(url_inicial)\n",
    "        if response_inicial.status_code == 200:\n",
    "            json_inicial = response_inicial.json()\n",
    "            total_paginas = json_inicial.get(\"totalPaginas\", 1)\n",
    "            for pagina in range(1, total_paginas + 1):\n",
    "                url = f\"{base_url}?dataInicial={data_inicial}&dataFinal={data_final}&codigoModalidadeContratacao={codigo_modalidade}&uf={uf}&tamanhoPagina={tamanho_pagina}&pagina={pagina}\"\n",
    "                response = requests.get(url)\n",
    "                if response.status_code == 200:\n",
    "                    dados = response.json().get(\"data\", [])\n",
    "                    processos.extend(dados)\n",
    "                else:\n",
    "                    st.error(f\"Erro na requisição para {url}: {response.status_code} - {response.text}\")\n",
    "        else:\n",
    "            st.error(f\"Erro na requisição para {url_inicial}: {response_inicial.status_code} - {response_inicial.text}\")\n",
    "    return processos\n",
    "\n",
    "def clean_illegal_chars(s):\n",
    "    \"\"\"\n",
    "    Remove caracteres de controle (ASCII < 32) de uma string.\n",
    "    \"\"\"\n",
    "    if isinstance(s, str):\n",
    "        return re.sub(r'[\\x00-\\x1F]+', ' ', s)\n",
    "    return s\n",
    "\n",
    "def process_data(processos):\n",
    "    \"\"\"\n",
    "    Converte a lista de processos (dicionários) em DataFrame, realiza\n",
    "    a normalização, renomeia a coluna 'objetoCompra' para 'objeto' (se existir),\n",
    "    converte tipos e realiza a limpeza dos dados.\n",
    "    \"\"\"\n",
    "    df = pd.json_normalize(processos)\n",
    "    if 'objetoCompra' in df.columns:\n",
    "        df.rename(columns={'objetoCompra': 'objeto'}, inplace=True)\n",
    "    # Conversões de tipo\n",
    "    if 'valorTotalEstimado' in df.columns:\n",
    "        df['valorTotalEstimado'] = pd.to_numeric(df['valorTotalEstimado'], errors='coerce')\n",
    "    if 'dataAberturaProposta' in df.columns:\n",
    "        df['dataAberturaProposta'] = pd.to_datetime(df['dataAberturaProposta'], format='%Y-%m-%dT%H:%M:%S', errors='coerce')\n",
    "    if 'dataInclusao' in df.columns:\n",
    "        df['dataInclusao'] = pd.to_datetime(df['dataInclusao'], format='%Y-%m-%dT%H:%M:%S', errors='coerce')\n",
    "    if 'dataEncerramentoProposta' in df.columns:\n",
    "        df['dataEncerramentoProposta'] = pd.to_datetime(df['dataEncerramentoProposta'], format='%Y-%m-%dT%H:%M:%S', errors='coerce')\n",
    "    # Limpeza de caracteres em colunas de texto\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].apply(clean_illegal_chars)\n",
    "    return df\n",
    "\n",
    "def to_excel(df_all, df_filtered):\n",
    "    \"\"\"\n",
    "    Gera um arquivo Excel em memória contendo duas planilhas:\n",
    "      - 'Todos' com todos os processos coletados\n",
    "      - 'Filtrados' com os processos após aplicação dos filtros.\n",
    "    \"\"\"\n",
    "    output = io.BytesIO()\n",
    "    writer = pd.ExcelWriter(output, engine='xlsxwriter')\n",
    "    df_all.to_excel(writer, sheet_name='Todos', index=False)\n",
    "    df_filtered.to_excel(writer, sheet_name='Filtrados', index=False)\n",
    "    writer.save()\n",
    "    processed_data = output.getvalue()\n",
    "    return processed_data\n",
    "\n",
    "def render_card(row):\n",
    "    \"\"\"\n",
    "    Renderiza um \"card\" HTML para exibir os dados principais de um processo.\n",
    "    \"\"\"\n",
    "    orgao = row.get(\"orgaoEntidade.razaoSocial\", \"N/D\")\n",
    "    uf = row.get(\"unidadeOrgao.ufSigla\", \"N/D\")\n",
    "    data_inclusao = row.get(\"dataInclusao\", \"N/D\")\n",
    "    processo = row.get(\"processo\", \"N/D\")\n",
    "    objeto = row.get(\"objeto\", \"N/D\")\n",
    "    valor_estimado = row.get(\"valorTotalEstimado\", \"N/D\")\n",
    "    \n",
    "    card_html = f\"\"\"\n",
    "    <div style=\"background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin-bottom: 10px;\n",
    "                box-shadow: 2px 2px 5px rgba(0,0,0,0.1);\">\n",
    "      <h4 style=\"margin-bottom: 5px;\">{orgao}</h4>\n",
    "      <p style=\"margin: 2px 0;\"><strong>UF:</strong> {uf}</p>\n",
    "      <p style=\"margin: 2px 0;\"><strong>Data Inclusão:</strong> {data_inclusao}</p>\n",
    "      <p style=\"margin: 2px 0;\"><strong>Processo:</strong> {processo}</p>\n",
    "      <p style=\"margin: 2px 0;\"><strong>Objeto:</strong> {objeto}</p>\n",
    "      <p style=\"margin: 2px 0;\"><strong>Valor Estimado:</strong> {valor_estimado}</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    st.markdown(card_html, unsafe_allow_html=True)\n",
    "\n",
    "# ============================================\n",
    "# Interface do Aplicativo com Streamlit\n",
    "# ============================================\n",
    "\n",
    "st.title(\"Visualização de Processos - PNCP\")\n",
    "\n",
    "# --- Parâmetros de Consulta (configurados na barra lateral) ---\n",
    "st.sidebar.header(\"Parâmetros de Consulta\")\n",
    "data_inicial_input = st.sidebar.text_input(\"Data Inicial (AAAAMMDD)\", \"20250101\")\n",
    "data_final_input = st.sidebar.text_input(\"Data Final (AAAAMMDD)\", \"20250331\")\n",
    "codigo_modalidade = st.sidebar.number_input(\"Código Modalidade\", value=6, step=1)\n",
    "tamanho_pagina = st.sidebar.number_input(\"Tamanho da Página\", value=50, step=10)\n",
    "ufs_input = st.sidebar.text_input(\"UFs (separadas por vírgula)\", \"ES,SP\")\n",
    "ufs = [uf.strip() for uf in ufs_input.split(\",\") if uf.strip()]\n",
    "\n",
    "# Botão para buscar os processos via API\n",
    "if st.sidebar.button(\"Buscar Processos\"):\n",
    "    with st.spinner(\"Buscando processos via API...\"):\n",
    "        processos = fetch_processos(data_inicial_input, data_final_input, codigo_modalidade, tamanho_pagina, ufs)\n",
    "        if processos:\n",
    "            st.session_state['processos'] = processos\n",
    "            st.success(f\"Foram coletados {len(processos)} processos.\")\n",
    "        else:\n",
    "            st.error(\"Nenhum processo foi coletado.\")\n",
    "\n",
    "# Se os processos foram coletados, processa os dados e exibe a UI\n",
    "if 'processos' in st.session_state:\n",
    "    df_all = process_data(st.session_state['processos'])\n",
    "    \n",
    "    # Layout em duas colunas: principal (cards) e filtros (lado direito)\n",
    "    col_main, col_filters = st.columns([3, 1])\n",
    "    \n",
    "    with col_filters:\n",
    "        st.subheader(\"Filtros\")\n",
    "        # Filtro baseado nas palavras-chave definidas no código original\n",
    "        opcoes = ['alimentício', 'alimento', 'alimentação', 'merenda', 'merenda escolar', 'gênero']\n",
    "        selected_keywords = st.multiselect(\"Palavras-chave\", opcoes, default=opcoes)\n",
    "    \n",
    "    # Aplica filtro na coluna \"objeto\"\n",
    "    if \"objeto\" in df_all.columns:\n",
    "        filtro = df_all[\"objeto\"].str.lower().str.contains('|'.join(selected_keywords), na=False)\n",
    "        df_filtered = df_all[filtro]\n",
    "    else:\n",
    "        df_filtered = df_all.copy()\n",
    "    \n",
    "    with col_main:\n",
    "        st.subheader(\"Processos\")\n",
    "        if df_filtered.empty:\n",
    "            st.write(\"Nenhum processo encontrado com os filtros aplicados.\")\n",
    "        else:\n",
    "            for _, row in df_filtered.iterrows():\n",
    "                render_card(row)\n",
    "    \n",
    "    # Botão para download do Excel com os dados completos e filtrados\n",
    "    excel_data = to_excel(df_all, df_filtered)\n",
    "    st.download_button(\n",
    "        label=\"Download Excel\",\n",
    "        data=excel_data,\n",
    "        file_name=f\"licitacoes_{datetime.now().strftime('%Y%m%d')}.xlsx\",\n",
    "        mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
